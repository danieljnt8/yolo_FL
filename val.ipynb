{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22e4613-2994-4da2-847a-02dbd6a2a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.callbacks import Callbacks\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import (LOGGER, box_iou, check_dataset, check_img_size, check_requirements, check_suffix, check_yaml,\n",
    "                           coco80_to_coco91_class, colorstr, increment_path, non_max_suppression, print_args,\n",
    "                           scale_coords, xywh2xyxy, xyxy2xywh)\n",
    "from utils.metrics import ConfusionMatrix, ap_per_class\n",
    "from utils.plots import output_to_target, plot_images, plot_val_study\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445a4d0-4790-48ff-af60-6adba405a681",
   "metadata": {},
   "source": [
    "## Code from VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bb0588-5ec8-4d7e-aabe-40acbb9735e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = '/home/stud-dajo/tph-yolov5/val.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958c9791-0cf7-44fb-9569-796c6b1a166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98049f55-d57c-43a8-97e9-597360e4d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_one_txt(predn, save_conf, shape, file):\n",
    "    # Save one txt result\n",
    "    gn = torch.tensor(shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "    for *xyxy, conf, cls in predn.tolist():\n",
    "        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "        with open(file, 'a') as f:\n",
    "            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "\n",
    "def save_one_json(predn, jdict, path, class_map):\n",
    "    # Save one JSON result {\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}\n",
    "    image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n",
    "    box = xyxy2xywh(predn[:, :4])  # xywh\n",
    "    box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
    "    for p, b in zip(predn.tolist(), box.tolist()):\n",
    "        jdict.append({'image_id': image_id,\n",
    "                      'category_id': class_map[int(p[5])],\n",
    "                      'bbox': [round(x, 3) for x in b],\n",
    "                      'score': round(p[4], 5)})\n",
    "\n",
    "\n",
    "def process_batch(detections, labels, iouv):\n",
    "    \"\"\"\n",
    "    Return correct predictions matrix. Both sets of boxes are in (x1, y1, x2, y2) format.\n",
    "    Arguments:\n",
    "        detections (Array[N, 6]), x1, y1, x2, y2, conf, class\n",
    "        labels (Array[M, 5]), class, x1, y1, x2, y2\n",
    "    Returns:\n",
    "        correct (Array[N, 10]), for 10 IoU levels\n",
    "    \"\"\"\n",
    "    correct = torch.zeros(detections.shape[0], iouv.shape[0], dtype=torch.bool, device=iouv.device)\n",
    "    iou = box_iou(labels[:, 1:], detections[:, :4])\n",
    "    x = torch.where((iou >= iouv[0]) & (labels[:, 0:1] == detections[:, 5]))  # IoU above threshold and classes match\n",
    "    if x[0].shape[0]:\n",
    "        matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()  # [label, detection, iou]\n",
    "        if x[0].shape[0] > 1:\n",
    "            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "            matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
    "            # matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "            matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n",
    "        matches = torch.Tensor(matches).to(iouv.device)\n",
    "        correct[matches[:, 1].long()] = matches[:, 2:3] >= iouv\n",
    "    return correct\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(data,\n",
    "        weights=None,  # model.pt path(s)\n",
    "        batch_size=32,  # batch size\n",
    "        imgsz=640,  # inference size (pixels)\n",
    "        conf_thres=0.001,  # confidence threshold\n",
    "        iou_thres=0.6,  # NMS IoU threshold\n",
    "        task='val',  # train, val, test, speed or study\n",
    "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        single_cls=False,  # treat as single-class dataset\n",
    "        augment=False,  # augmented inference\n",
    "        verbose=False,  # verbose output\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_hybrid=False,  # save label+prediction hybrid results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_json=False,  # save a COCO-JSON results file\n",
    "        project=ROOT / 'runs/val',  # save to project/name\n",
    "        name='exp',  # save to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        model=None,\n",
    "        dataloader=None,\n",
    "        save_dir=Path(''),\n",
    "        plots=True,\n",
    "        callbacks=Callbacks(),\n",
    "        compute_loss=None,\n",
    "        ):\n",
    "    # Initialize/load model and set device\n",
    "    training = model is not None\n",
    "    if training:  # called by train.py\n",
    "        device = next(model.parameters()).device  # get model device\n",
    "\n",
    "    else:  # called directly\n",
    "        device = select_device(device, batch_size=batch_size)\n",
    "\n",
    "        # Directories\n",
    "        save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "        # Load model\n",
    "        check_suffix(weights, '.pt')\n",
    "        model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "        gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
    "        imgsz = check_img_size(imgsz, s=gs)  # check image size\n",
    "\n",
    "        # Multi-GPU disabled, incompatible with .half() https://github.com/ultralytics/yolov5/issues/99\n",
    "        # if device.type != 'cpu' and torch.cuda.device_count() > 1:\n",
    "        #     model = nn.DataParallel(model)\n",
    "\n",
    "        # Data\n",
    "        data = check_dataset(data)  # check\n",
    "\n",
    "    # Half\n",
    "    half &= device.type != 'cpu'  # half precision only supported on CUDA\n",
    "    model.half() if half else model.float()\n",
    "\n",
    "    # Configure\n",
    "    model.eval()\n",
    "    is_coco = isinstance(data.get('val'), str) and data['val'].endswith('coco/val2017.txt')  # COCO dataset\n",
    "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "    niou = iouv.numel()\n",
    "\n",
    "    # Dataloader\n",
    "    if not training:\n",
    "        if device.type != 'cpu':\n",
    "            model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "        pad = 0.0 if task == 'speed' else 0.5\n",
    "        task = task if task in ('train', 'val', 'test') else 'val'  # path to train/val/test images\n",
    "        dataloader = create_dataloader(data[task], imgsz, batch_size, gs, single_cls, pad=pad, rect=True,\n",
    "                                       prefix=colorstr(f'{task}: '))[0]\n",
    "\n",
    "    seen = 0\n",
    "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
    "    class_map = coco80_to_coco91_class() if is_coco else list(range(1000))\n",
    "    s = ('%20s' + '%11s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "    dt, p, r, f1, mp, mr, map50, map = [0.0, 0.0, 0.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    loss = torch.zeros(3, device=device)\n",
    "    jdict, stats, ap, ap_class = [], [], [], []\n",
    "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "        t1 = time_sync()\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        targets = targets.to(device)\n",
    "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Run model\n",
    "        out, train_out = model(img, augment=augment)  # inference and training outputs\n",
    "        dt[1] += time_sync() - t2\n",
    "\n",
    "        # Compute loss\n",
    "        if compute_loss:\n",
    "            loss += compute_loss([x.float() for x in train_out], targets)[1]  # box, obj, cls\n",
    "\n",
    "        # Run NMS\n",
    "        targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
    "        lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
    "        t3 = time_sync()\n",
    "        out = non_max_suppression(out, conf_thres, iou_thres, labels=lb, multi_label=True, agnostic=single_cls)\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        # Statistics per image\n",
    "        for si, pred in enumerate(out):\n",
    "            labels = targets[targets[:, 0] == si, 1:]\n",
    "            nl = len(labels)\n",
    "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "            path, shape = Path(paths[si]), shapes[si][0]\n",
    "            seen += 1\n",
    "\n",
    "            if len(pred) == 0:\n",
    "                if nl:\n",
    "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "                continue\n",
    "\n",
    "            # Predictions\n",
    "            if single_cls:\n",
    "                pred[:, 5] = 0\n",
    "            predn = pred.clone()\n",
    "            scale_coords(img[si].shape[1:], predn[:, :4], shape, shapes[si][1])  # native-space pred\n",
    "\n",
    "            # Evaluate\n",
    "            if nl:\n",
    "                tbox = xywh2xyxy(labels[:, 1:5])  # target boxes\n",
    "                scale_coords(img[si].shape[1:], tbox, shape, shapes[si][1])  # native-space labels\n",
    "                labelsn = torch.cat((labels[:, 0:1], tbox), 1)  # native-space labels\n",
    "                correct = process_batch(predn, labelsn, iouv)\n",
    "                if plots:\n",
    "                    confusion_matrix.process_batch(predn, labelsn)\n",
    "            else:\n",
    "                correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool)\n",
    "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))  # (correct, conf, pcls, tcls)\n",
    "\n",
    "            # Save/log\n",
    "            if save_txt:\n",
    "                save_one_txt(predn, save_conf, shape, file=save_dir / 'labels' / (path.stem + '.txt'))\n",
    "            if save_json:\n",
    "                save_one_json(predn, jdict, path, class_map)  # append to COCO-JSON dictionary\n",
    "            callbacks.run('on_val_image_end', pred, predn, path, names, img[si])\n",
    "\n",
    "        # Plot images\n",
    "        if plots and batch_i < 3:\n",
    "            f = save_dir / f'val_batch{batch_i}_labels.jpg'  # labels\n",
    "            Thread(target=plot_images, args=(img, targets, paths, f, names), daemon=True).start()\n",
    "            f = save_dir / f'val_batch{batch_i}_pred.jpg'  # predictions\n",
    "            Thread(target=plot_images, args=(img, output_to_target(out), paths, f, names), daemon=True).start()\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
    "    if len(stats) and stats[0].any():\n",
    "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, save_dir=save_dir, names=names)\n",
    "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
    "    else:\n",
    "        nt = torch.zeros(1)\n",
    "\n",
    "    # Print results\n",
    "    pf = '%20s' + '%11i' * 2 + '%11.3g' * 4  # print format\n",
    "    LOGGER.info(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "\n",
    "    # Print results per class\n",
    "    if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):\n",
    "        for i, c in enumerate(ap_class):\n",
    "            LOGGER.info(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
    "\n",
    "    # Print speeds\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    if not training:\n",
    "        shape = (batch_size, 3, imgsz, imgsz)\n",
    "        LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {shape}' % t)\n",
    "\n",
    "    # Plots\n",
    "    if plots:\n",
    "        confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))\n",
    "        callbacks.run('on_val_end')\n",
    "\n",
    "    # Save JSON\n",
    "    if save_json and len(jdict):\n",
    "        w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
    "        anno_json = str(Path(data.get('path', '../coco')) / 'annotations/instances_val2017.json')  # annotations json\n",
    "        pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
    "        LOGGER.info(f'\\nEvaluating pycocotools mAP... saving {pred_json}...')\n",
    "        with open(pred_json, 'w') as f:\n",
    "            json.dump(jdict, f)\n",
    "\n",
    "        try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
    "            check_requirements(['pycocotools'])\n",
    "            from pycocotools.coco import COCO\n",
    "            from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "            anno = COCO(anno_json)  # init annotations api\n",
    "            pred = anno.loadRes(pred_json)  # init predictions api\n",
    "            eval = COCOeval(anno, pred, 'bbox')\n",
    "            if is_coco:\n",
    "                eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
    "            eval.evaluate()\n",
    "            eval.accumulate()\n",
    "            eval.summarize()\n",
    "            map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
    "        except Exception as e:\n",
    "            LOGGER.info(f'pycocotools unable to run: {e}')\n",
    "\n",
    "    # Return results\n",
    "    model.float()  # for training\n",
    "    if not training:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    maps = np.zeros(nc) + map\n",
    "    for i, c in enumerate(ap_class):\n",
    "        maps[c] = ap[i]\n",
    "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t\n",
    "\n",
    "\n",
    "def parse_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='batch size')\n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.001, help='confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.6, help='NMS IoU threshold')\n",
    "    parser.add_argument('--task', default='val', help='train, val, test, speed or study')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--verbose', action='store_true', help='report mAP by class')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "    parser.add_argument('--save-hybrid', action='store_true', help='save label+prediction hybrid results to *.txt')\n",
    "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
    "    parser.add_argument('--save-json', action='store_true', help='save a COCO-JSON results file')\n",
    "    parser.add_argument('--project', default=ROOT / 'runs/val', help='save to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')\n",
    "    opt = parser.parse_args()\n",
    "    opt.data = check_yaml(opt.data)  # check YAML\n",
    "    opt.save_json |= opt.data.endswith('coco.yaml')\n",
    "    opt.save_txt |= opt.save_hybrid\n",
    "    print_args(FILE.stem, opt)\n",
    "    return opt\n",
    "\n",
    "def parse_opt_1(data=None, weights=None, batch_size=None, imgsz=None, conf_thres=None,\n",
    "              iou_thres=None, task=None, device=None, single_cls=None, augment=None,\n",
    "              verbose=None, save_txt=None, save_hybrid=None, save_conf=None, save_json=None,\n",
    "              project=None, name=None, exist_ok=None, half=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data', type=str, default=data or (ROOT / 'data/coco128.yaml'), help='dataset.yaml path')\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default=weights or (ROOT / 'yolov5s.pt'), help='model.pt path(s)')\n",
    "    parser.add_argument('--batch-size', type=int, default=batch_size or 32, help='batch size')\n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=imgsz or 640, help='inference size (pixels)')\n",
    "    parser.add_argument('--conf-thres', type=float, default=conf_thres or 0.001, help='confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=iou_thres or 0.6, help='NMS IoU threshold')\n",
    "    parser.add_argument('--task', default=task or 'val', help='train, val, test, speed or study')\n",
    "    parser.add_argument('--device', default=device or '', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--single-cls', action='store_true' if single_cls else 'store_false', help='treat as single-class dataset')\n",
    "    parser.add_argument('--augment', action='store_true' if augment else 'store_false', help='augmented inference')\n",
    "    parser.add_argument('--verbose', action='store_true' if verbose else 'store_false', help='report mAP by class')\n",
    "    parser.add_argument('--save-txt', action='store_true' if save_txt else 'store_false', help='save results to *.txt')\n",
    "    parser.add_argument('--save-hybrid', action='store_true' if save_hybrid else 'store_false', help='save label+prediction hybrid results to *.txt')\n",
    "    parser.add_argument('--save-conf', action='store_true' if save_conf else 'store_false', help='save confidences in --save-txt labels')\n",
    "    parser.add_argument('--save-json', action='store_true' if save_json else 'store_false', help='save a COCO-JSON results file')\n",
    "    parser.add_argument('--project', default=project or (ROOT / 'runs/val'), help='save to project/name')\n",
    "    parser.add_argument('--name', default=name or 'exp', help='save to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true' if exist_ok else 'store_false', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--half', action='store_true' if half else 'store_false', help='use FP16 half-precision inference')\n",
    "    \n",
    "    opt = parser.parse_args([])\n",
    "    opt.data = check_yaml(opt.data)  # check YAML\n",
    "    opt.save_json |= opt.data.endswith('coco.yaml')\n",
    "    opt.save_txt |= opt.save_hybrid\n",
    "    print_args(\"FILE_STEM\", opt)\n",
    "    return opt\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(requirements=ROOT / 'requirements.txt', exclude=('tensorboard', 'thop'))\n",
    "\n",
    "    if opt.task in ('train', 'val', 'test'):  # run normally\n",
    "        run(**vars(opt))\n",
    "\n",
    "    elif opt.task == 'speed':  # speed benchmarks\n",
    "        # python val.py --task speed --data coco.yaml --batch 1 --weights yolov5n.pt yolov5s.pt...\n",
    "        for w in opt.weights if isinstance(opt.weights, list) else [opt.weights]:\n",
    "            run(opt.data, weights=w, batch_size=opt.batch_size, imgsz=opt.imgsz, conf_thres=.25, iou_thres=.45,\n",
    "                device=opt.device, save_json=False, plots=False)\n",
    "\n",
    "    elif opt.task == 'study':  # run over a range of settings and save/plot\n",
    "        # python val.py --task study --data coco.yaml --iou 0.7 --weights yolov5n.pt yolov5s.pt...\n",
    "        x = list(range(256, 1536 + 128, 128))  # x axis (image sizes)\n",
    "        for w in opt.weights if isinstance(opt.weights, list) else [opt.weights]:\n",
    "            f = f'study_{Path(opt.data).stem}_{Path(w).stem}.txt'  # filename to save to\n",
    "            y = []  # y axis\n",
    "            for i in x:  # img-sizey\n",
    "\n",
    "                LOGGER.info(f'\\nRunning {f} point {i}...')\n",
    "                r, _, t = run(opt.data, weights=w, batch_size=opt.batch_size, imgsz=i, conf_thres=opt.conf_thres,\n",
    "                              iou_thres=opt.iou_thres, device=opt.device, save_json=opt.save_json, plots=False)\n",
    "                y.append(r + t)  # results and times\n",
    "            np.savetxt(f, y, fmt='%10.4g')  # save\n",
    "        os.system('zip -r study.zip study_*.txt')\n",
    "        plot_val_study(x=x)  # plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98644c12-b210-4574-b2b4-89add21f5b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFILE_STEM: \u001b[0mdata=./data/VisDrone.yaml, weights=./weights/yolov5l-xs-1.pt, batch_size=1, imgsz=1996, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=True, augment=False, verbose=False, save_txt=True, save_hybrid=True, save_conf=False, save_json=True, project=runs/val, name=v5l-xs, exist_ok=True, half=True\n"
     ]
    }
   ],
   "source": [
    "opt = parse_opt_1(\n",
    "    weights='./weights/yolov5l-xs-1.pt',\n",
    "    imgsz=1996,\n",
    "    data='./data/VisDrone.yaml',\n",
    "    augment=True,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    task='val',\n",
    "    batch_size=1,\n",
    "    verbose=True,\n",
    "    name='v5l-xs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa318ff-5c57-44b4-a8d8-ca1cab0d002f",
   "metadata": {},
   "source": [
    "## CODE VAL End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f84e418b-2067-4ee0-8c29-ac0b46fdda8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data='./data/VisDrone.yaml', weights='./weights/yolov5l-xs-1.pt', batch_size=1, imgsz=1996, conf_thres=0.001, iou_thres=0.6, task='val', device='', single_cls=True, augment=False, verbose=False, save_txt=True, save_hybrid=True, save_conf=False, save_json=True, project=PosixPath('runs/val'), name='v5l-xs', exist_ok=True, half=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74564c8c-d460-4bce-a196-d7d915961f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "half=False\n",
    "augment =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25a4903-8da6-484b-ad9c-ef15c98cb098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 052dfeb torch 2.1.1+cu121 CPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = select_device(opt.device, batch_size=opt.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614c9fdd-0494-4402-8759-2822dd6ff4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 570 layers, 60425780 parameters, 0 gradients, 145.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = attempt_load(opt.weights, map_location=device)  # load FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2d0903-6da5-4f11-b2e4-22c656c44f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (4): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (6): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (8): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (9): C3TR(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): TransformerBlock(\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (tr): Sequential(\n",
       "          (0): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): Concat()\n",
       "    (13): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (16): Concat()\n",
       "    (17): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (19): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (20): Concat()\n",
       "    (21): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (22): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (24): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (25): Concat()\n",
       "    (26): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (27): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (28): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (29): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (30): Concat()\n",
       "    (31): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=11, stride=1, padding=5, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (32): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (33): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (34): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (35): Concat()\n",
       "    (36): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=11, stride=1, padding=5, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (37): C3TR(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): TransformerBlock(\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (tr): Sequential(\n",
       "          (0): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (38): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (39): Detect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(128, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(512, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e59cdee-460e-4b32-88b4-d26960af19e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (4): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (6): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (8): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (9): C3TR(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): TransformerBlock(\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (tr): Sequential(\n",
       "          (0): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Conv(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): Concat()\n",
       "    (13): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (16): Concat()\n",
       "    (17): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (19): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (20): Concat()\n",
       "    (21): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (22): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (24): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (25): Concat()\n",
       "    (26): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (27): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (28): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (29): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (30): Concat()\n",
       "    (31): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=11, stride=1, padding=5, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (32): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (33): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (34): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (35): Concat()\n",
       "    (36): SPP(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (1): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)\n",
       "        (2): MaxPool2d(kernel_size=11, stride=1, padding=5, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (37): C3TR(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): TransformerBlock(\n",
       "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (tr): Sequential(\n",
       "          (0): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): TransformerLayer(\n",
       "            (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (ma): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (38): CBAM(\n",
       "      (channel_attention): ChannelAttentionModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (shared_MLP): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=64, out_features=1024, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttentionModule(\n",
       "        (conv2d): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (39): Detect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(128, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(512, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad52bc5-3769-4362-b8f8-73e42a53ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = max(int(model.stride.max()), 32)\n",
    "nc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5624e6-a6c1-470f-b149-d8d096b98fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1e5490-feb9-4fe6-8fb6-89343b3c52bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "niou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eddfea75-1783-42ef-9235-4979c491f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17591f8b-da90-4ccd-a483-ed8b213ef1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f9abdb-5427-4bfc-90a4-88558fc92ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = check_dataset(opt.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26deea51-dd5d-4877-947c-faa3dcb7fe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../datasets/VisDrone',\n",
       " 'train': '../datasets/VisDrone/VisDrone2019-DET-train/images',\n",
       " 'val': '../datasets/VisDrone/VisDrone2019-DET-val/images',\n",
       " 'test': '../datasets/VisDrone/VisDrone2019-DET-test-challenge/images',\n",
       " 'nc': 10,\n",
       " 'names': ['pedestrian',\n",
       "  'people',\n",
       "  'bicycle',\n",
       "  'car',\n",
       "  'van',\n",
       "  'truck',\n",
       "  'tricycle',\n",
       "  'awning-tricycle',\n",
       "  'bus',\n",
       "  'motor'],\n",
       " 'download': 'from utils.general import download, os, Path\\n\\ndef visdrone2yolo(dir):\\n    from PIL import Image\\n    from tqdm import tqdm\\n\\n    def convert_box(size, box):\\n        # Convert VisDrone box to YOLO xywh box\\n        dw = 1. / size[0]\\n        dh = 1. / size[1]\\n        return (box[0] + box[2] / 2) * dw, (box[1] + box[3] / 2) * dh, box[2] * dw, box[3] * dh\\n\\n    (dir / \\'labels\\').mkdir(parents=True, exist_ok=True)  # make labels directory\\n    pbar = tqdm((dir / \\'annotations\\').glob(\\'*.txt\\'), desc=f\\'Converting {dir}\\')\\n    for f in pbar:\\n        img_size = Image.open((dir / \\'images\\' / f.name).with_suffix(\\'.jpg\\')).size\\n        lines = []\\n        with open(f, \\'r\\') as file:  # read annotation.txt\\n            for row in [x.split(\\',\\') for x in file.read().strip().splitlines()]:\\n                if row[4] == \\'0\\':  # VisDrone \\'ignored regions\\' class 0\\n                    continue\\n                cls = int(row[5]) - 1\\n                box = convert_box(img_size, tuple(map(int, row[:4])))\\n                lines.append(f\"{cls} {\\' \\'.join(f\\'{x:.6f}\\' for x in box)}\\\\n\")\\n                with open(str(f).replace(os.sep + \\'annotations\\' + os.sep, os.sep + \\'labels\\' + os.sep), \\'w\\') as fl:\\n                    fl.writelines(lines)  # write label.txt\\n\\n\\n# Download\\ndir = Path(yaml[\\'path\\'])  # dataset root dir\\nurls = [\\'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-train.zip\\',\\n        \\'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-val.zip\\',\\n        \\'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-test-dev.zip\\',\\n        \\'https://github.com/ultralytics/yolov5/releases/download/v1.0/VisDrone2019-DET-test-challenge.zip\\']\\ndownload(urls, dir=dir)\\n\\n# Convert\\nfor d in \\'VisDrone2019-DET-train\\', \\'VisDrone2019-DET-val\\', \\'VisDrone2019-DET-test-dev\\':\\n    visdrone2yolo(dir / d)  # convert VisDrone annotations to YOLO labels\\n'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f924e78a-83af-424b-9a64-7d7fa82d2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/VisDrone/VisDrone2019-DET-val/labels.cache' images and labels... 548 found, 0 missing, 0 empty, 0 corrupted: 100%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader(data[task], opt.imgsz, opt.batch_size, gs, opt.single_cls, pad=pad, rect=True,\n",
    "                                       prefix=colorstr(f'{task}: '))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da1e6061-8ca9-4a13-95d1-891030117687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/VisDrone.yaml'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "954f93e1-8a1f-4e52-98a5-92cb0767e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = 0\n",
    "confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "435546b6-b935-45dc-83ec-8e4e5a8643ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'pedestrian',\n",
       " 1: 'people',\n",
       " 2: 'bicycle',\n",
       " 3: 'car',\n",
       " 4: 'van',\n",
       " 5: 'truck',\n",
       " 6: 'tricycle',\n",
       " 7: 'awning-tricycle',\n",
       " 8: 'bus',\n",
       " 9: 'motor'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ede6ae2-9423-4da7-8422-466cad49ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_coco = isinstance(data.get('val'), str) and data['val'].endswith('coco/val2017.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c8d63b-665e-4860-892c-86400055a81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e877b0b5-c51c-459b-96fd-fa078e01aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = coco80_to_coco91_class() if is_coco else list(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b0ee2d5-91ec-4f45-ac32-25a8f2b1f6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce1ec55a-49fd-4205-96e4-c920eea8af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ('%20s' + '%11s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba03f249-3c4b-4883-83bd-597da56699c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d86a0c-199f-4e95-a8ba-43bf7b9c714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, p, r, f1, mp, mr, map50, map = [0.0, 0.0, 0.0], 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "loss = torch.zeros(3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a4f0c19-b515-4153-b29a-95650eacce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdict, stats, ap, ap_class = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86b92560-58c8-4722-8a6a-79ce36f5a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|                       | 0/548 [00:57<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          ...,\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706]],\n",
      "\n",
      "         [[0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          ...,\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706]],\n",
      "\n",
      "         [[0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          ...,\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706],\n",
      "          [0.44706, 0.44706, 0.44706,  ..., 0.44706, 0.44706, 0.44706]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "    t1 = time_sync()\n",
    "    img = img.to(device, non_blocking=True)\n",
    "    \n",
    "    img = img.half() if half else img.float()\n",
    "    img = img / 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    targets = targets.to(device)\n",
    "    nb, _, height, width = img.shape \n",
    "\n",
    "    out, train_out = model(img, augment=augment)\n",
    "    print(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb0fe1dc-7678-4e19-9ccc-0b52d2db3238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1152, 2016])\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20b0993b-1b57-491f-b046-f5d9f448bf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8329f44a-94f6-4289-b80c-ef6377a0db73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3070168, 15])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dc49a1b-b045-41de-86d6-360d5cad04bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1152, 2016])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b1105f4-6f9c-4155-b06e-e4f39ad667ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cf3c997-ebcb-4354-8328-536175f0c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0.00000,    0.00000,  259.14084,  124.99976,   16.13554,   20.53371],\n",
      "        [   0.00000,    0.00000,  265.74228,  112.53322,   20.53654,   39.59988],\n",
      "        [   0.00000,    0.00000,  293.61444,  122.06686,   17.60388,   44.00035],\n",
      "        [   0.00000,    0.00000, 1350.52356,  126.46621,   16.13550,   41.06633],\n",
      "        [   0.00000,    0.00000, 1568.35962,  119.13281,   11.73462,   29.33356],\n",
      "        [   0.00000,    0.00000, 1585.22925,  116.19991,   16.13562,   38.13342],\n",
      "        [   0.00000,    0.00000, 1627.77063,  116.93370,   16.13550,   39.59987],\n",
      "        [   0.00000,    0.00000, 1751.72400,  983.73364,   85.08081,  118.79968],\n",
      "        [   0.00000,    0.00000,   30.30237,  964.66638,   39.60674,  139.33319],\n",
      "        [   0.00000,    0.00000,   54.50770,  689.66638,   79.21346,  111.46625],\n",
      "        [   0.00000,    0.00000,   91.17979,  680.86658,   35.20576,   82.13373],\n",
      "        [   0.00000,    0.00000,  581.12787,  738.06616,   85.08081,  120.26721],\n",
      "        [   0.00000,    0.00000, 1102.61487,   46.53381,   16.13550,   27.86711],\n",
      "        [   0.00000,    0.00000, 1104.08313,   48.00026,   16.13550,   27.86711],\n",
      "        [   0.00000,    0.00000, 1260.30957,  187.33359,   23.47119,   30.80003],\n",
      "        [   0.00000,    0.00000, 1331.45337,  712.40039,   54.27588,  107.06689],\n",
      "        [   0.00000,    0.00000, 1340.98950,  106.66628,   14.66919,   33.73293],\n",
      "        [   0.00000,    0.00000,  251.07304,  128.66644,   20.53653,   22.00018],\n",
      "        [   0.00000,    0.00000, 1346.12256,  133.06694,   16.13562,   30.80002],\n",
      "        [   0.00000,    0.00000,   38.37214,  146.99994,   55.74229,   61.60004],\n",
      "        [   0.00000,    0.00000,   51.57306,  139.66655,   82.14612,   46.93327],\n",
      "        [   0.00000,    0.00000,   64.04181,  100.80046,  107.08363,   48.39972],\n",
      "        [   0.00000,    0.00000,   92.64612,  132.33315,  129.08847,   46.93326],\n",
      "        [   0.00000,    0.00000,  146.18994,  213.73312,  145.22404,   68.93343],\n",
      "        [   0.00000,    0.00000,  148.39041,  121.33305,  117.35388,   45.46679],\n",
      "        [   0.00000,    0.00000,  226.86972,  215.93338,  145.22400,   67.46696],\n",
      "        [   0.00000,    0.00000,  247.40625,   99.33289,   92.41638,   45.46680],\n",
      "        [   0.00000,    0.00000,  309.01587,  102.26691,   92.41641,   48.39971],\n",
      "        [   0.00000,    0.00000,  394.83075,  102.99959,   73.34619,   41.06632],\n",
      "        [   0.00000,    0.00000,  449.10675,  106.66628,   85.08078,   39.59986],\n",
      "        [   0.00000,    0.00000,  495.31494,  158.73380,  115.88553,   49.86617],\n",
      "        [   0.00000,    0.00000,  504.84900,  137.46631,   90.94806,   39.59987],\n",
      "        [   0.00000,    0.00000,  508.51584,  109.60031,   86.54706,   45.46680],\n",
      "        [   0.00000,    0.00000,  514.38513,  144.79970,  112.95291,   45.46680],\n",
      "        [   0.00000,    0.00000,  665.47644,  567.20020,  206.83368,  168.66693],\n",
      "        [   0.00000,    0.00000, 1134.15381,  333.26651,   93.88257,   82.13373],\n",
      "        [   0.00000,    0.00000, 1247.10681,  130.13290,   49.87500,   42.53278],\n",
      "        [   0.00000,    0.00000, 1386.46350,  133.06693,   46.94043,   48.39970],\n",
      "        [   0.00000,    0.00000, 1494.28125,  238.66623,  165.76062,   60.13361],\n",
      "        [   0.00000,    0.00000, 1500.14844,  166.06720,  130.55481,   49.86617],\n",
      "        [   0.00000,    0.00000, 1517.01819,  151.40042,  143.75781,   44.00035],\n",
      "        [   0.00000,    0.00000, 1599.16650,   75.13359,   99.74988,   35.20051],\n",
      "        [   0.00000,    0.00000, 1607.96631,  258.46616,  187.76538,   61.60004],\n",
      "        [   0.00000,    0.00000, 1635.83862,  322.26645,  173.09631,   71.86633],\n",
      "        [   0.00000,    0.00000, 1636.57275,  275.33319,  198.03357,   71.86636],\n",
      "        [   0.00000,    0.00000, 1940.95581,  358.93335,  129.08838,  130.53345],\n",
      "        [   0.00000,    0.00000,   98.51540,   67.80019,  143.75771,   73.33279],\n",
      "        [   0.00000,    0.00000,  373.56006,  146.99994,   63.07791,   61.60004],\n",
      "        [   0.00000,    0.00000,  430.77069,  125.73355,  107.08365,   60.13359],\n",
      "        [   0.00000,    0.00000,  934.65381,  205.66707,   76.27881,   82.13376],\n",
      "        [   0.00000,    0.00000, 1191.36438,  165.33340,   52.80957,   63.06648],\n",
      "        [   0.00000,    0.00000, 1509.68457,  188.06625,  146.69031,   70.39990],\n",
      "        [   0.00000,    0.00000, 1516.28406,  125.73355,  112.95288,   60.13359],\n",
      "        [   0.00000,    0.00000,   47.90625,  960.99976,   74.81250,  108.53333],\n",
      "        [   0.00000,    0.00000,   68.44278,  731.46655,  115.88556,   89.46710],\n",
      "        [   0.00000,    0.00000,  574.52844,  773.26672,   77.74713,   99.73346],\n",
      "        [   0.00000,    0.00000, 1104.08325,   53.86721,   13.20300,   22.00018],\n",
      "        [   0.00000,    0.00000, 1255.90869,  201.26657,   23.47119,   35.20050],\n",
      "        [   0.00000,    0.00000, 1332.92163,  752.73291,   51.34143,   99.73346],\n",
      "        [   0.00000,    0.00000, 1343.18994,  119.13281,   16.13550,   23.46664]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8b74dcd-7319-4267-94a6-58ac21db2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hybrid=False\n",
    "single_cls = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "595f5fa0-ccfd-4713-91cb-1e689311154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thres = 0.001\n",
    "iou_thres = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34f5477f-f59e-4207-93c2-a0cc00118c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25147dfa-801c-4724-b40e-c5c5abe30498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b223c2a9-2c3b-43be-9da7-61646f61c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = non_max_suppression(out, conf_thres, iou_thres, labels=lb, multi_label=True, agnostic=single_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3072127-17ad-457c-b289-1392f3174192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 6])\n"
     ]
    }
   ],
   "source": [
    "for si,pred in enumerate(out):\n",
    "    labels = targets[targets[:, 0] == si, 1:]\n",
    "    nl = len(labels)\n",
    "    tcls = labels[:, 0].tolist()\n",
    "    path, shape = Path(paths[si]), shapes[si][0]\n",
    "    seen += 1\n",
    "    predn = pred.clone()\n",
    "    scale_coords(img[si].shape[1:], predn[:, :4], shape, shapes[si][1])  # native-space pred\n",
    "    tbox = xywh2xyxy(labels[:, 1:5])\n",
    "    scale_coords(img[si].shape[1:], tbox, shape, shapes[si][1])  #\n",
    "    labelsn = torch.cat((labels[:, 0:1], tbox), 1)\n",
    "   \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2f7822d-302e-4479-81fc-c2d3a6476592",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = targets[targets[:, 0] == si, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d3fee6f-a6b9-450b-9f3d-aababf23a4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 5])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e750d45c-15d0-4a8f-a6ed-0dcab7bbb8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = process_batch(predn, labelsn, iouv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7fe1bdb7-8e61-485b-b8cd-4671d2bc0d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cff6bea9-38a3-46de-b5d0-38ba94ef17d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct[296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9cf14a08-0e7d-4f87-afdd-2b036a0c0536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.metrics.ConfusionMatrix at 0x7fde702cbc70>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f504f51d-cc58-48a5-b77a-367fa265d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = predn\n",
    "labels = labelsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4ab215f6-e0a0-4fa8-a2a0-f7bbee500ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = torch.zeros(detections.shape[0], iouv.shape[0], dtype=torch.bool, device=iouv.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ff57637f-fd41-4890-a917-a58139c825d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = box_iou(labels[:, 1:], detections[:, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26eb3f-2cec-42ee-a91b-5e6ad9f27486",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.where((iou >= iouv[0]) & (labels[:, 0:1] == detections[:, 5]))  # IoU above threshold and classes match*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "649eead3-b0fb-4dc9-8d92-29f76d03d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if x[0].shape[0]:\n",
    "    matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()  # [label, detection, iou]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9e8cf7fd-3840-4fbe-834e-b22b6e7f07de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a50612ba-e7df-4e60-abe6-146890c7d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "if x[0].shape[0]:\n",
    "    matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()  # [label, detection, iou]\n",
    "    if x[0].shape[0] > 1:\n",
    "            matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "            matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
    "            matches = matches[np.unique(matches[:, 0], return_index=True)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cecb33cb-29f9-4a98-87b9-2ca8ec92a730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cde317e-cbac-4301-8d8d-9ccc6bbb7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = torch.Tensor(matches).to(iouv.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f214e09-5de9-40f1-b2fe-17fa46fc0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct[matches[:, 1].long()] = matches[:, 2:3] >= iouv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd3e3a3f-8713-4c6f-9590-38e4e4499cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 18,   0],\n",
      "        [ 18,   1],\n",
      "        [ 18,   2],\n",
      "        [ 18,   3],\n",
      "        [ 18,   4],\n",
      "        [ 18,   5],\n",
      "        [ 18,   6],\n",
      "        [ 18,   7],\n",
      "        [ 18,   8],\n",
      "        [ 22,   0],\n",
      "        [ 22,   1],\n",
      "        [ 22,   2],\n",
      "        [ 22,   3],\n",
      "        [ 22,   4],\n",
      "        [ 22,   5],\n",
      "        [ 22,   6],\n",
      "        [ 31,   0],\n",
      "        [ 31,   1],\n",
      "        [ 31,   2],\n",
      "        [ 31,   3],\n",
      "        [ 31,   4],\n",
      "        [ 31,   5],\n",
      "        [ 31,   6],\n",
      "        [ 34,   0],\n",
      "        [ 34,   1],\n",
      "        [ 34,   2],\n",
      "        [ 34,   3],\n",
      "        [ 34,   4],\n",
      "        [ 34,   5],\n",
      "        [ 34,   6],\n",
      "        [ 38,   0],\n",
      "        [ 38,   1],\n",
      "        [ 38,   2],\n",
      "        [ 38,   3],\n",
      "        [ 38,   4],\n",
      "        [ 38,   5],\n",
      "        [ 38,   6],\n",
      "        [ 38,   7],\n",
      "        [ 43,   0],\n",
      "        [ 43,   1],\n",
      "        [ 43,   2],\n",
      "        [ 43,   3],\n",
      "        [ 71,   0],\n",
      "        [ 71,   1],\n",
      "        [ 71,   2],\n",
      "        [ 71,   3],\n",
      "        [ 73,   0],\n",
      "        [ 73,   1],\n",
      "        [ 75,   0],\n",
      "        [ 75,   1],\n",
      "        [ 75,   2],\n",
      "        [ 75,   3],\n",
      "        [ 75,   4],\n",
      "        [ 88,   0],\n",
      "        [ 88,   1],\n",
      "        [ 88,   2],\n",
      "        [ 88,   3],\n",
      "        [ 88,   4],\n",
      "        [ 89,   0],\n",
      "        [ 89,   1],\n",
      "        [ 89,   2],\n",
      "        [ 89,   3],\n",
      "        [ 89,   4],\n",
      "        [ 94,   0],\n",
      "        [ 94,   1],\n",
      "        [ 94,   2],\n",
      "        [ 94,   3],\n",
      "        [ 94,   4],\n",
      "        [ 94,   5],\n",
      "        [111,   0],\n",
      "        [111,   1],\n",
      "        [111,   2],\n",
      "        [111,   3],\n",
      "        [112,   0],\n",
      "        [112,   1],\n",
      "        [123,   0],\n",
      "        [123,   1],\n",
      "        [123,   2],\n",
      "        [123,   3],\n",
      "        [123,   4],\n",
      "        [123,   5],\n",
      "        [123,   6],\n",
      "        [123,   7],\n",
      "        [123,   8],\n",
      "        [127,   0],\n",
      "        [127,   1],\n",
      "        [127,   2],\n",
      "        [127,   3],\n",
      "        [127,   4],\n",
      "        [136,   0],\n",
      "        [136,   1],\n",
      "        [136,   2],\n",
      "        [136,   3],\n",
      "        [136,   4],\n",
      "        [136,   5],\n",
      "        [137,   0],\n",
      "        [137,   1],\n",
      "        [137,   2],\n",
      "        [137,   3],\n",
      "        [137,   4],\n",
      "        [137,   5],\n",
      "        [137,   6],\n",
      "        [137,   7],\n",
      "        [145,   0],\n",
      "        [177,   0],\n",
      "        [177,   1],\n",
      "        [177,   2],\n",
      "        [226,   0],\n",
      "        [226,   1],\n",
      "        [226,   2],\n",
      "        [226,   3],\n",
      "        [226,   4],\n",
      "        [226,   5],\n",
      "        [226,   6],\n",
      "        [226,   7],\n",
      "        [237,   0],\n",
      "        [237,   1],\n",
      "        [237,   2],\n",
      "        [237,   3],\n",
      "        [237,   4],\n",
      "        [244,   0],\n",
      "        [244,   1],\n",
      "        [244,   2],\n",
      "        [244,   3],\n",
      "        [244,   4],\n",
      "        [246,   0],\n",
      "        [246,   1],\n",
      "        [246,   2],\n",
      "        [246,   3],\n",
      "        [246,   4],\n",
      "        [246,   5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.nonzero(correct, as_tuple=False)\n",
    "\n",
    "print(indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4601c29c-7820-4cee-bc17-7cac06c2c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.00000,  31.00000,   0.82413],\n",
      "        [  2.00000,  22.00000,   0.80298],\n",
      "        [  3.00000,  34.00000,   0.81166],\n",
      "        [  4.00000,  43.00000,   0.69488],\n",
      "        [  5.00000,  18.00000,   0.91025],\n",
      "        [  6.00000,  38.00000,   0.86246],\n",
      "        [  7.00000,  73.00000,   0.59322],\n",
      "        [  8.00000, 145.00000,   0.54356],\n",
      "        [  9.00000, 136.00000,   0.75438],\n",
      "        [ 10.00000,  94.00000,   0.78315],\n",
      "        [ 11.00000,  88.00000,   0.73774],\n",
      "        [ 13.00000,  71.00000,   0.69170],\n",
      "        [ 14.00000, 177.00000,   0.62261],\n",
      "        [ 15.00000, 137.00000,   0.85195],\n",
      "        [ 16.00000, 111.00000,   0.65725],\n",
      "        [ 17.00000, 112.00000,   0.55810],\n",
      "        [ 18.00000,  89.00000,   0.71083],\n",
      "        [ 26.00000,  75.00000,   0.71600],\n",
      "        [ 27.00000, 123.00000,   0.92472],\n",
      "        [ 53.00000, 246.00000,   0.75206],\n",
      "        [ 54.00000, 226.00000,   0.87520],\n",
      "        [ 55.00000, 244.00000,   0.74083],\n",
      "        [ 56.00000, 237.00000,   0.71806],\n",
      "        [ 59.00000, 127.00000,   0.70454]])\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "93b92775-f9c5-43d9-a777-98d365476ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.82413],\n",
       "        [0.80298],\n",
       "        [0.81166],\n",
       "        [0.69488],\n",
       "        [0.91025],\n",
       "        [0.86246],\n",
       "        [0.59322],\n",
       "        [0.54356],\n",
       "        [0.75438],\n",
       "        [0.78315],\n",
       "        [0.73774],\n",
       "        [0.69170],\n",
       "        [0.62261],\n",
       "        [0.85195],\n",
       "        [0.65725],\n",
       "        [0.55810],\n",
       "        [0.71083],\n",
       "        [0.71600],\n",
       "        [0.92472],\n",
       "        [0.75206],\n",
       "        [0.87520],\n",
       "        [0.74083],\n",
       "        [0.71806],\n",
       "        [0.70454]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[:, 2:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "22b78f95-9d1f-458c-9dc3-c9359be86bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.50000, 0.55000, 0.60000, 0.65000, 0.70000, 0.75000, 0.80000, 0.85000, 0.90000, 0.95000])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iouv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cc6fedaf-498e-40f3-b700-add99af2b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7ccdabc2-fd80-44f1-9d30-507b45e8df44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[:, 2:3] >= iouv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce527593-1149-4210-8623-90a175fc7de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 31,  22,  34,  43,  18,  38,  73, 145, 136,  94,  88,  71, 177, 137, 111, 112,  89,  75, 123, 246, 226, 244, 237, 127])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[:, 1].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e3127314-5024-41e1-8975-0dfa19d05985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False, False, False])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f438a-5a03-4c99-8600-c8a28bb65708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
